{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define relevant variables for the Machine Learning task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def data_loader(data_dir,\n",
    "                batch_size,\n",
    "                random_seed=42,\n",
    "                valid_size=0.1,\n",
    "                shuffle=True,\n",
    "                test=False):\n",
    "  \n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "\n",
    "    if test:\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root=data_dir, train=False,\n",
    "            download=True, transform=transform,\n",
    "        )\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    " \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "# CIFAR10 dataset \n",
    "train_loader, valid_loader = data_loader(data_dir='./data', batch_size=batch_size)\n",
    "\n",
    "test_loader = data_loader(data_dir='./data', batch_size=batch_size, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a ResidualBlock\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-34\n",
    "# there are 4 blocks in the architecture,\n",
    "# containing 3, 4, 6, and 3 layers respectively\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64  # in_channels\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # there are 4 blocks in the architecture,\n",
    "        # containing 3, 4, 6, and 3 layers respectively\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    # 构造由残差块ResidualBlock组成的模块\n",
    "    # block: 残差块; planes: 输出通道数; blocks: 模块中残差块的数目\n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        downsample = None\n",
    "        # 第一个模块之后的每个模块在第一个残差块里将上一个模块的通道数翻倍（使用1x1卷积），并将高和宽减半\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample)) # 每个模块的第一个残差块\n",
    "        self.inplanes = planes  # Note: 之后的残差块通道数相同\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [1, 3, 224, 224]     [1, 10]              --                   True\n",
       "├─Sequential (conv1)                     [1, 3, 224, 224]     [1, 64, 112, 112]    --                   True\n",
       "│    └─Conv2d (0)                        [1, 3, 224, 224]     [1, 64, 112, 112]    9,472                True\n",
       "│    └─BatchNorm2d (1)                   [1, 64, 112, 112]    [1, 64, 112, 112]    128                  True\n",
       "│    └─ReLU (2)                          [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
       "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
       "├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
       "│    └─ResidualBlock (0)                 [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─Sequential (conv2)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    └─ResidualBlock (1)                 [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─Sequential (conv2)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    └─ResidualBlock (2)                 [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─Sequential (conv2)           [1, 64, 56, 56]      [1, 64, 56, 56]      37,056               True\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
       "│    └─ResidualBlock (0)                 [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 64, 56, 56]      [1, 128, 28, 28]     74,112               True\n",
       "│    │    └─Sequential (conv2)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     8,576                True\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    └─ResidualBlock (1)                 [1, 128, 28, 28]     [1, 128, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─Sequential (conv2)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    └─ResidualBlock (2)                 [1, 128, 28, 28]     [1, 128, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─Sequential (conv2)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    └─ResidualBlock (3)                 [1, 128, 28, 28]     [1, 128, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─Sequential (conv2)           [1, 128, 28, 28]     [1, 128, 28, 28]     147,840              True\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
       "│    └─ResidualBlock (0)                 [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 128, 28, 28]     [1, 256, 14, 14]     295,680              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     33,536               True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    └─ResidualBlock (1)                 [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    └─ResidualBlock (2)                 [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    └─ResidualBlock (3)                 [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    └─ResidualBlock (4)                 [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    └─ResidualBlock (5)                 [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─Sequential (conv2)           [1, 256, 14, 14]     [1, 256, 14, 14]     590,592              True\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
       "│    └─ResidualBlock (0)                 [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 256, 14, 14]     [1, 512, 7, 7]       1,181,184            True\n",
       "│    │    └─Sequential (conv2)           [1, 512, 7, 7]       [1, 512, 7, 7]       2,360,832            True\n",
       "│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       132,608              True\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    └─ResidualBlock (1)                 [1, 512, 7, 7]       [1, 512, 7, 7]       --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 512, 7, 7]       [1, 512, 7, 7]       2,360,832            True\n",
       "│    │    └─Sequential (conv2)           [1, 512, 7, 7]       [1, 512, 7, 7]       2,360,832            True\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    └─ResidualBlock (2)                 [1, 512, 7, 7]       [1, 512, 7, 7]       --                   True\n",
       "│    │    └─Sequential (conv1)           [1, 512, 7, 7]       [1, 512, 7, 7]       2,360,832            True\n",
       "│    │    └─Sequential (conv2)           [1, 512, 7, 7]       [1, 512, 7, 7]       2,360,832            True\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --\n",
       "├─Linear (fc)                            [1, 512]             [1, 10]              5,130                True\n",
       "========================================================================================================================\n",
       "Total params: 21,298,314\n",
       "Trainable params: 21,298,314\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.67\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 59.81\n",
       "Params size (MB): 85.19\n",
       "Estimated Total Size (MB): 145.61\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
    "# print(model)\n",
    "summary(model=model, input_size=(1, 3, 224, 224), col_width=20, \n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'], \n",
    "        row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [704/704], Loss: 1.5582\n",
      "Accuracy of the network on the 5000 validation images: 53.94 %\n",
      "Epoch [2/20], Step [704/704], Loss: 0.8758\n",
      "Accuracy of the network on the 5000 validation images: 69.22 %\n",
      "Epoch [3/20], Step [704/704], Loss: 0.4167\n",
      "Accuracy of the network on the 5000 validation images: 75.98 %\n",
      "Epoch [4/20], Step [704/704], Loss: 0.8871\n",
      "Accuracy of the network on the 5000 validation images: 78.14 %\n",
      "Epoch [5/20], Step [704/704], Loss: 1.6262\n",
      "Accuracy of the network on the 5000 validation images: 80.02 %\n",
      "Epoch [6/20], Step [704/704], Loss: 0.0743\n",
      "Accuracy of the network on the 5000 validation images: 80.74 %\n",
      "Epoch [7/20], Step [704/704], Loss: 0.1247\n",
      "Accuracy of the network on the 5000 validation images: 77.8 %\n",
      "Epoch [8/20], Step [704/704], Loss: 0.4560\n",
      "Accuracy of the network on the 5000 validation images: 80.26 %\n",
      "Epoch [9/20], Step [704/704], Loss: 0.1756\n",
      "Accuracy of the network on the 5000 validation images: 81.8 %\n",
      "Epoch [10/20], Step [704/704], Loss: 0.9592\n",
      "Accuracy of the network on the 5000 validation images: 80.66 %\n",
      "Epoch [11/20], Step [704/704], Loss: 0.6719\n",
      "Accuracy of the network on the 5000 validation images: 81.66 %\n",
      "Epoch [12/20], Step [704/704], Loss: 1.0379\n",
      "Accuracy of the network on the 5000 validation images: 77.74 %\n",
      "Epoch [13/20], Step [704/704], Loss: 0.0155\n",
      "Accuracy of the network on the 5000 validation images: 76.08 %\n",
      "Epoch [14/20], Step [704/704], Loss: 0.0793\n",
      "Accuracy of the network on the 5000 validation images: 81.6 %\n",
      "Epoch [15/20], Step [704/704], Loss: 0.9166\n",
      "Accuracy of the network on the 5000 validation images: 80.62 %\n",
      "Epoch [16/20], Step [704/704], Loss: 0.5757\n",
      "Accuracy of the network on the 5000 validation images: 79.46 %\n",
      "Epoch [17/20], Step [704/704], Loss: 0.3089\n",
      "Accuracy of the network on the 5000 validation images: 82.6 %\n",
      "Epoch [18/20], Step [704/704], Loss: 0.1065\n",
      "Accuracy of the network on the 5000 validation images: 81.12 %\n",
      "Epoch [19/20], Step [704/704], Loss: 0.2828\n",
      "Accuracy of the network on the 5000 validation images: 81.16 %\n",
      "Epoch [20/20], Step [704/704], Loss: 0.5645\n",
      "Accuracy of the network on the 5000 validation images: 82.34 %\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()   # sets the module in training mode\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    model.eval()    # sets the module in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print('Accuracy of the network on the {} validation images: {} %' \n",
    "              .format(5000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.29 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()    # sets the module in evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %' \n",
    "          .format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING A MODEL FROM PYTORCH TO ONNX\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "x = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32, requires_grad=True)\n",
    "torch.onnx.export(model,                                        # model being run\n",
    "                  x,                                            # model input (or a tuple for multiple inputs)\n",
    "                  \"ResNet.onnx\",                                # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,                           # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,                             # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                     # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],                      # the model's input names\n",
    "                  output_names = ['output'],                    # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},   # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
