{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积格式说明\n",
    "## 对[1, 1, H, W]的卷积实现\n",
    "**卷积运算转换为：im2col矩阵 * kernel展开矩阵**  \n",
    "**im2col行的数目：与kernel矩阵做运算的子矩阵的个数=im2colH = outputH * outputW**  \n",
    "**im2col列的数目：kernel中元素的个数=im2colW=kernelH * kernelW**  \n",
    "**kernel直接展开为列向量即可**\n",
    "\n",
    "## 对[1, C, H, W]的卷积实现\n",
    "**kernel维度：kernelO, kernelI, kernelH, kernelW**  \n",
    "**im2col列的数目：kernel中元素的个数im2colW = kernelI * kernelH * kernelW**  \n",
    "***这里必须注意展开后kernel的转置和矩阵乘法计算完成后的HWC到CHW的转换***\n",
    "\n",
    "## 对[B, C, H, W]的卷积实现\n",
    "**增加一个batch维度即可**  \n",
    "**这里的im2col的做法是：行的数目乘以batchSize，即在行的后续增加batch的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1, 1, H, W]的卷积实现\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "inputH, inputW = 7, 7\n",
    "kernelH, kernelW = 3, 3\n",
    "input = np.arange(0, inputH * inputW).reshape(inputH, inputW).astype(np.int32)\n",
    "kernel = np.arange(kernelH * kernelW, dtype=np.int32).reshape(kernelH, kernelW)\n",
    "# print(input)\n",
    "# print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my convolution implementation:\n",
      "[[ 420  456  492  528  564]\n",
      " [ 672  708  744  780  816]\n",
      " [ 924  960  996 1032 1068]\n",
      " [1176 1212 1248 1284 1320]\n",
      " [1428 1464 1500 1536 1572]]\n",
      "\n",
      "torch convolution implementation:\n",
      "tensor([[ 420,  456,  492,  528,  564],\n",
      "        [ 672,  708,  744,  780,  816],\n",
      "        [ 924,  960,  996, 1032, 1068],\n",
      "        [1176, 1212, 1248, 1284, 1320],\n",
      "        [1428, 1464, 1500, 1536, 1572]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 获取特征图的形状\n",
    "inputH, inputW = input.shape\n",
    "# 获取filter kernel的形状\n",
    "kernelH, kernelW = kernel.shape\n",
    "# 设置填充和步幅\n",
    "padding = 0\n",
    "stride = 1\n",
    "# 计算卷积操作后输出特征图的行数和列数，也就是特征图的大小\n",
    "outputH = int((inputH - kernelH + padding + stride) / stride)\n",
    "outputW = int((inputW - kernelW + padding + stride) / stride)\n",
    "# print(outputH, outputW)\n",
    "\n",
    "# 计算卷积转换矩阵im2col的形状\n",
    "im2colH = outputH * outputW\n",
    "im2colW = kernelH * kernelW\n",
    "im2colInput = np.zeros([im2colH, im2colW], dtype=np.int32)\n",
    "\n",
    "# 将输入特征图input继续卷积展开\n",
    "# i，j这两层循环遍历输出的高度和宽度，即在行和列这两个维度上与kernel矩阵分别运算的次数\n",
    "# 同时im2col矩阵的行(也可以是列，是具体实现而定) = outputH * outputW\n",
    "for i in range(outputH):\n",
    "    for j in range(outputW):\n",
    "        # i，j也是kernel在input移动时在input上的起始点索引\n",
    "        # ii，jj是kernel维度上的索引\n",
    "        for ii in range(kernelH):\n",
    "            inputRowidx = i + ii       # input上的行索引\n",
    "            for jj in range(kernelW):\n",
    "                inputColidx = j + jj   # input上的列索引\n",
    "                im2colInput[i * outputW + j][ii * kernelW + jj] = input[inputRowidx][inputColidx]\n",
    "# print(im2colInput)\n",
    "                \n",
    "# 将卷积核展开\n",
    "im2colKernel = kernel.reshape(kernelH * kernelW, -1)\n",
    "# 计算卷积输出\n",
    "output = np.matmul(im2colInput, im2colKernel).reshape(outputH, outputW)\n",
    "print(\"my convolution implementation:\")\n",
    "print(output)\n",
    "\n",
    "# pytorch验证计算结果正确性\n",
    "inputTensor = input.reshape(1, 1, inputH, inputW)\n",
    "weightTensor = kernel.reshape(1, 1, kernelH, kernelW)\n",
    "inputTensor = torch.from_numpy(inputTensor)\n",
    "weightTensor = torch.from_numpy(weightTensor)\n",
    "\n",
    "output = F.conv2d(inputTensor, weightTensor, padding=padding, stride=stride)\n",
    "output = output.reshape(outputH, outputW)\n",
    "print(\"\\ntorch convolution implementation:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1, C, H, W]的卷积实现\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "intputC, inputH, inputW = 5, 7, 7\n",
    "kernelO, kernelI, kernelH, kernelW = 3, 5, 3, 3\n",
    "input = np.arange(0, intputC * inputH * inputW).reshape(intputC, inputH, inputW).astype(np.int32)\n",
    "kernel = np.arange(kernelO * kernelI * kernelH * kernelW, dtype=np.int32)\\\n",
    "           .reshape(kernelO, kernelI, kernelH, kernelW)\n",
    "# kernel = np.ones([kernelO, kernelI, kernelH, kernelW], dtype=np.int32)\n",
    "# print(input)\n",
    "# print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my convolution implementation:\n",
      "[[[145290 146280 147270 148260 149250]\n",
      "  [152220 153210 154200 155190 156180]\n",
      "  [159150 160140 161130 162120 163110]\n",
      "  [166080 167070 168060 169050 170040]\n",
      "  [173010 174000 174990 175980 176970]]\n",
      "\n",
      " [[359940 362955 365970 368985 372000]\n",
      "  [381045 384060 387075 390090 393105]\n",
      "  [402150 405165 408180 411195 414210]\n",
      "  [423255 426270 429285 432300 435315]\n",
      "  [444360 447375 450390 453405 456420]]\n",
      "\n",
      " [[574590 579630 584670 589710 594750]\n",
      "  [609870 614910 619950 624990 630030]\n",
      "  [645150 650190 655230 660270 665310]\n",
      "  [680430 685470 690510 695550 700590]\n",
      "  [715710 720750 725790 730830 735870]]]\n",
      "\n",
      "torch convolution implementation:\n",
      "tensor([[[145290, 146280, 147270, 148260, 149250],\n",
      "         [152220, 153210, 154200, 155190, 156180],\n",
      "         [159150, 160140, 161130, 162120, 163110],\n",
      "         [166080, 167070, 168060, 169050, 170040],\n",
      "         [173010, 174000, 174990, 175980, 176970]],\n",
      "\n",
      "        [[359940, 362955, 365970, 368985, 372000],\n",
      "         [381045, 384060, 387075, 390090, 393105],\n",
      "         [402150, 405165, 408180, 411195, 414210],\n",
      "         [423255, 426270, 429285, 432300, 435315],\n",
      "         [444360, 447375, 450390, 453405, 456420]],\n",
      "\n",
      "        [[574590, 579630, 584670, 589710, 594750],\n",
      "         [609870, 614910, 619950, 624990, 630030],\n",
      "         [645150, 650190, 655230, 660270, 665310],\n",
      "         [680430, 685470, 690510, 695550, 700590],\n",
      "         [715710, 720750, 725790, 730830, 735870]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 获取特征图的形状\n",
    "inputC, inputH, inputW = input.shape\n",
    "# 获取filter kernel的形状\n",
    "kernelO, kernelI, kernelH, kernelW = kernel.shape\n",
    "# 设置填充和步幅\n",
    "padding = 0\n",
    "stride = 1\n",
    "# 计算卷积操作后输出特征图的维度信息\n",
    "outputC = kernelO\n",
    "outputH = int((inputH - kernelH + padding + stride) / stride)\n",
    "outputW = int((inputW - kernelW + padding + stride) / stride)\n",
    "# print(outputC, outputH, outputW)\n",
    "\n",
    "# 计算卷积转换矩阵im2col的形状\n",
    "im2colH = outputH * outputW\n",
    "im2colW = kernelI * kernelH * kernelW   # Notice: 与[1, 1, H, W]不同\n",
    "im2colInput = np.zeros([im2colH, im2colW], dtype=np.int32)\n",
    "\n",
    "# 将输入特征图input继续卷积展开\n",
    "# i，j这两层循环遍历输出的高度和宽度，即在行和列这两个维度上与kernel矩阵分别运算的次数\n",
    "# 同时im2col矩阵的行(也可以是列，是具体实现而定) = outputH * outputW\n",
    "for i in range(outputH):\n",
    "    for j in range(outputW):\n",
    "        # i，j也是kernel在input移动时在input上的起始点索引\n",
    "        # cc, ii，jj是kernel维度上的索引\n",
    "        for cc in range(kernelI):          # channel维度\n",
    "            for ii in range(kernelH):\n",
    "                inputRowidx = i + ii       # input上的行索引\n",
    "                for jj in range(kernelW):\n",
    "                    inputColidx = j + jj   # input上的列索引\n",
    "                    im2colInput[i * outputW + j][cc * kernelH * kernelW + ii * kernelW + jj] \\\n",
    "                        = input[cc][inputRowidx][inputColidx]\n",
    "# print(im2colInput)\n",
    "# print(im2colInput.shape)\n",
    "\n",
    "# 将卷积核展开\n",
    "im2colKernel = kernel.reshape(kernelO, -1).T    # Notice: 这里的转置是必须的\n",
    "# print(im2colKernel)\n",
    "# print(im2colKernel.shape)\n",
    "\n",
    "# 计算卷积输出\n",
    "# output = np.matmul(im2colInput, im2colKernel).reshape(outputC, outputH, outputW)  # Error!!!维度信息错误了！！！\n",
    "output = np.matmul(im2colInput, im2colKernel).reshape(outputH, outputW, outputC)    # Pass, 计算完成后是HWC\n",
    "output = np.transpose(output, (2, 0, 1))                                            # 需要transpose为CHW\n",
    "print(\"my convolution implementation:\")\n",
    "print(output)\n",
    "\n",
    "# pytorch验证计算结果正确性\n",
    "inputTensor = input.reshape(1, inputC, inputH, inputW)\n",
    "weightTensor = kernel.reshape(kernelO, kernelI, kernelH, kernelW)\n",
    "inputTensor = torch.from_numpy(inputTensor)\n",
    "weightTensor = torch.from_numpy(weightTensor)\n",
    "\n",
    "output = F.conv2d(inputTensor, weightTensor, padding=padding, stride=stride)\n",
    "output = output.reshape(outputC, outputH, outputW)\n",
    "print(\"\\ntorch convolution implementation:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [B, C, H, W]的卷积实现\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "inputB, intputC, inputH, inputW = 8, 5, 7, 7\n",
    "kernelO, kernelI, kernelH, kernelW = 3, 5, 3, 3\n",
    "input = np.arange(0, inputB * intputC * inputH * inputW).reshape(inputB, intputC, inputH, inputW).astype(np.int32)\n",
    "kernel = np.arange(kernelO * kernelI * kernelH * kernelW, dtype=np.int32)\\\n",
    "           .reshape(kernelO, kernelI, kernelH, kernelW)\n",
    "# kernel = np.ones([kernelO, kernelI, kernelH, kernelW], dtype=np.int32)\n",
    "# print(input.shape)\n",
    "# print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im2colInput.shape:  (200, 45)\n",
      "im2colKernel.shape:  (45, 3)\n",
      "output.shape:  (8, 3, 5, 5)\n",
      "pyoutput.shape:  torch.Size([8, 3, 5, 5])\n",
      "PASS!\n"
     ]
    }
   ],
   "source": [
    "# 获取特征图的形状\n",
    "inputB, inputC, inputH, inputW = input.shape\n",
    "# 获取filter kernel的形状\n",
    "kernelO, kernelI, kernelH, kernelW = kernel.shape\n",
    "# 设置填充和步幅\n",
    "padding = 0\n",
    "stride = 1\n",
    "# 计算卷积操作后输出特征图的维度信息\n",
    "outputB = inputB    # batch size\n",
    "outputC = kernelO\n",
    "outputH = int((inputH - kernelH + padding + stride) / stride)\n",
    "outputW = int((inputW - kernelW + padding + stride) / stride)\n",
    "# print(outputC, outputH, outputW)\n",
    "\n",
    "# 计算卷积转换矩阵im2col的形状\n",
    "im2colH = outputB * outputH * outputW   # Notice: 与[1, C, H, W]不同\n",
    "im2colW = kernelI * kernelH * kernelW   # Notice: 与[1, 1, H, W]不同\n",
    "im2colInput = np.zeros([im2colH, im2colW], dtype=np.int32)\n",
    "\n",
    "# 将输入特征图input继续卷积展开\n",
    "# i，j这两层循环遍历输出的高度和宽度，即在行和列这两个维度上与kernel矩阵分别运算的次数\n",
    "# 同时im2col矩阵的行(也可以是列，是具体实现而定) = outputH * outputW\n",
    "for b in range(outputB):                        # batch维度上的loop\n",
    "    for i in range(outputH):\n",
    "        for j in range(outputW):\n",
    "            # i，j也是kernel在input移动时在input上的起始点索引\n",
    "            # cc, ii，jj是kernel维度上的索引\n",
    "            for cc in range(kernelI):           # channel维度\n",
    "                for ii in range(kernelH):\n",
    "                    inputRowidx = i + ii        # input上的行索引\n",
    "                    for jj in range(kernelW):\n",
    "                        inputColidx = j + jj    # input上的列索引\n",
    "                        im2colInput[b * outputH * outputW + i * outputW + j][cc * kernelH * kernelW + ii * kernelW + jj] \\\n",
    "                            = input[b][cc][inputRowidx][inputColidx]\n",
    "# print(im2colInput)\n",
    "print(\"im2colInput.shape: \", im2colInput.shape)\n",
    "\n",
    "# 将卷积核展开\n",
    "im2colKernel = kernel.reshape(kernelO, -1).T    # Notice: 这里的转置是必须的\n",
    "# print(im2colKernel)\n",
    "print(\"im2colKernel.shape: \", im2colKernel.shape)\n",
    "\n",
    "# 计算卷积输出\n",
    "output = np.matmul(im2colInput, im2colKernel).reshape(outputB, outputH, outputW, outputC)\n",
    "output = np.transpose(output, (0, 3, 1, 2))     # 需要transpose: BHWC转换到BCHW\n",
    "# print(\"my convolution implementation:\")\n",
    "# print(output)\n",
    "print(\"output.shape: \", output.shape)\n",
    "\n",
    "# pytorch验证计算结果正确性\n",
    "inputTensor = input.reshape(inputB, inputC, inputH, inputW)\n",
    "weightTensor = kernel.reshape(kernelO, kernelI, kernelH, kernelW)\n",
    "inputTensor = torch.from_numpy(inputTensor)\n",
    "weightTensor = torch.from_numpy(weightTensor)\n",
    "\n",
    "pyoutput = F.conv2d(inputTensor, weightTensor, padding=padding, stride=stride)\n",
    "# print(\"\\ntorch convolution implementation:\")\n",
    "# print(pyoutput)\n",
    "print(\"pyoutput.shape: \", pyoutput.shape)\n",
    "\n",
    "# Convert tensor to ndarray\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "np.testing.assert_allclose(to_numpy(pyoutput), output, rtol=1e-03, atol=1e-05)\n",
    "print(\"PASS!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
